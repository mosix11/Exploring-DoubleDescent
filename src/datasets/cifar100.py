import torch
from torchvision import datasets
import torchvision as tv
import torchvision.transforms.v2 as transforms
from torch.utils.data import Dataset, DataLoader, random_split, Subset
from .base_classification_dataset import BaseClassificationDataset
from .dataset_wrappers import DatasetWithIndex, LabelRemapper, NoisyClassificationDataset, BinarizedClassificationDataset
import torch.distributed as dist

import os
from pathlib import Path
import random
import numpy as np
from typing import Tuple, List, Union, Dict

class CIFAR100(BaseClassificationDataset):
    
    def __init__(
        self,
        data_dir: Path = Path("./data").absolute(),
        img_size: Union[tuple, list] = (32, 32),
        grayscale: bool = False,
        normalize_imgs: bool = False,
        flatten: bool = False,
        augmentations: Union[list, None] = None,
        train_transforms: Union[tv.transforms.Compose, transforms.Compose] = None,
        val_transforms: Union[tv.transforms.Compose, transforms.Compose] = None,
        **kwargs
    ) -> None:
        self.img_size = img_size
        self.grayscale = grayscale
        self.normalize_imgs = normalize_imgs
        self.flatten = flatten
        
        self.augmentations = [] if augmentations == None else augmentations
        self._train_transforms = train_transforms
        self._val_transforms = val_transforms
        
        if (train_transforms or val_transforms) and (augmentations != None):
            raise ValueError('You should either pass augmentations, or train and validation transforms.')
        
        
        data_dir.mkdir(exist_ok=True, parents=True)
        dataset_dir = data_dir / 'CIFAR100'
        dataset_dir.mkdir(exist_ok=True, parents=True)
        
        super().__init__(
            dataset_name='CIFAR100',
            dataset_dir=dataset_dir,
            num_classes=100,
            **kwargs,  
        )
        
    def load_train_set(self):
        self.train_transforms = self.get_transforms(train=True)
        root = self.dataset_dir

        if self.is_distributed():
            if self.is_node_leader():
                _ = datasets.CIFAR100(root=root, train=True, download=True)  # no transform needed
            dist.barrier()
            trainset = datasets.CIFAR100(root=root, train=True, transform=self.train_transforms, download=False)
        else:
            trainset = datasets.CIFAR100(root=root, train=True, transform=self.train_transforms, download=True)

        self._class_names = trainset.classes
        return trainset

    def load_validation_set(self):
        return None

    def load_test_set(self):
        self.val_transforms = self.get_transforms(train=False)
        root = self.dataset_dir

        if self.is_distributed():
            if self.is_node_leader():
                _ = datasets.CIFAR100(root=root, train=False, download=True)  # no transform needed
            dist.barrier()
            testset = datasets.CIFAR100(root=root, train=False, transform=self.val_transforms, download=False)
        else:
            testset = datasets.CIFAR100(root=root, train=False, transform=self.val_transforms, download=True)

        return testset
    
    def get_transforms(self, train=True):
        if self._train_transforms and train:
            return self._train_transforms
        elif self._val_transforms and not train:
            return self._val_transforms
        
        trnsfrms = []
        if self.img_size != (32, 32):
            trnsfrms.append(transforms.Resize(self.img_size))
        if self.grayscale:
            trnsfrms.append(transforms.Grayscale(num_output_channels=1))
        if len(self.augmentations) > 0 and train:
            trnsfrms.extend(self.augmentations)
        trnsfrms.extend([
            transforms.ToImage(),
            transforms.ToDtype(torch.float32, scale=True),
        ])
        if self.normalize_imgs:
            mean, std = ((0.5,), (0.5,)) if self.grayscale else ((0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762)) # Values Specific to CIFAR-100
            trnsfrms.append(transforms.Normalize(mean, std))
        if self.flatten:
            trnsfrms.append(transforms.Lambda(lambda x: torch.flatten(x)))
        return transforms.Compose(trnsfrms)

    def get_class_names(self):
        return self._class_names

    def get_identifier(self):
        identifier = 'cifar100|'
        # identifier += f'ln{self.label_noise}|'
        identifier += 'aug|' if len(self.augmentations) > 0 else 'noaug|'
        identifier += f'subsample{self.subsample_size}' if self.subsample_size != (-1, -1) else 'full'
        return identifier
    

