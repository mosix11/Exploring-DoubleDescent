import torch
import torchvision as tv
from torchvision import datasets
import torchvision.transforms.v2 as transforms
from .base_classification_dataset import BaseClassificationDataset
from typing import Tuple, List, Union, Dict
from pathlib import Path
import torch.distributed as dist

class CIFAR10(BaseClassificationDataset):
    def __init__(
        self,
        data_dir: Path = Path("./data").absolute(),
        img_size: Union[tuple, list] = (32, 32),
        grayscale: bool = False,
        normalize_imgs: bool = False,
        flatten: bool = False,
        augmentations: Union[list, None] = None,
        train_transforms: Union[tv.transforms.Compose, transforms.Compose] = None,
        val_transforms: Union[tv.transforms.Compose, transforms.Compose] = None,
        **kwargs
    ) -> None:
        self.img_size = img_size
        self.grayscale = grayscale
        self.normalize_imgs = normalize_imgs
        self.flatten = flatten
        self.augmentations = [] if augmentations == None else augmentations
        
        self._train_transforms = train_transforms
        self._val_transforms = val_transforms
        
        if (train_transforms or val_transforms) and (augmentations != None):
            raise ValueError('You should either pass augmentations, or train and validation transforms.')
        
        data_dir.mkdir(exist_ok=True, parents=True)
        dataset_dir = data_dir / 'CIFAR10'
        dataset_dir.mkdir(exist_ok=True, parents=True)
        
        super().__init__(
            dataset_name='CIFAR10',
            dataset_dir=dataset_dir,
            num_classes=10,
            **kwargs,  
        )


    def load_train_set(self):
        self.train_transforms = self.get_transforms(train=True)
        root = self.dataset_dir
        if self.is_distributed():
            if self.is_node_leader():
                _ = datasets.CIFAR10(root=root, train=True, transform=self.train_transforms, download=True)
            dist.barrier()
            trainset = datasets.CIFAR10(root=root, train=True, transform=self.train_transforms, download=False)
        else:
            trainset = datasets.CIFAR10(root=root, train=True, transform=self.train_transforms, download=True)
                
        self._class_names = trainset.classes
        return trainset
    
    def load_validation_set(self):
        return None
    
    def load_test_set(self):
        self.val_transforms = self.get_transforms(train=False)
        root = self.dataset_dir
        
        if self.is_distributed():
            if self.is_node_leader():
                _ = datasets.CIFAR10(root=root, train=False, transform=self.val_transforms , download=True)
            dist.barrier()
            testset = datasets.CIFAR10(root=root, train=False, transform=self.val_transforms , download=False)
        else:
            testset = datasets.CIFAR10(root=root, train=False, transform=self.val_transforms , download=True)

        return testset

    def get_transforms(self, train=True):
        if self._train_transforms and train:
            return self._train_transforms
        elif self._val_transforms and not train:
            return self._val_transforms
        
        trnsfrms = []
        if self.img_size != (32, 32):
            trnsfrms.append(transforms.Resize(self.img_size))
        if self.grayscale:
            trnsfrms.append(transforms.Grayscale(num_output_channels=1))
        if len(self.augmentations) > 0 and train:
            trnsfrms.extend(self.augmentations)
        trnsfrms.extend([
            transforms.ToImage(),
            transforms.ToDtype(torch.float32, scale=True),
        ])
        
        if self.normalize_imgs:
            mean, std = ((0.5,), (0.5,)) if self.grayscale else ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
            trnsfrms.append(transforms.Normalize(mean, std))
        if self.flatten:
            trnsfrms.append(transforms.Lambda(lambda x: torch.flatten(x)))
        return transforms.Compose(trnsfrms)


    def get_class_names(self):
        return self._class_names 

    def get_identifier(self):
        identifier = 'cifar10|'
        # identifier += f'ln{self.label_noise}|'
        identifier += 'aug|' if len(self.augmentations) > 0 else 'noaug|'
        identifier += f'subsample{self.subsample_size}' if self.subsample_size != (-1, -1) else 'full'
        return identifier
    
    

    



            