global_seed: &global_seed 11

# https://arxiv.org/pdf/1812.11118
# Belkin weight reuse is reusing the final weights of the previous model capacity up until the `interpolation_ths`
# + initializing the first model with `init_xavier_uniform` and models after `interpolation_ths` with `init_normal` using `mean=0.0, std=0.1`
weight_reuse: True


# noise_config:
#   noise_rate: 0.0
#   noise_type: 'symmetric'
#   seed: 8


dataset:
  name: "cifar10"
  num_classes: &num_classes 10
  img_size: [8, 8]
  batch_size: 512
  class_subset: [3, 5] # dog and cat
  subsample_size: [960, 500] # first item is the size of train split subsample and the second is for test set
  normalize_imgs: False
  grayscale: True
  flatten: True
  valset_ratio: 0.0
  num_workers: 8
  seed: *global_seed

model:
  type: 'fc1'
  input_dim: 64
  hidden_dims: [
        2,
        4,
        8,
        12,
        16,
        20,
        24,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        38,
        48,
        64,
        96,
        128,
        256,
        384,
        512,
        1024,
        2048,
    ]
  output_dim: *num_classes
  interpolation_ths: 30
  loss_fn:
    type: 'MSE'
  metrics: ['ACC']




trainer:
  max_epochs: 6000
  optimizer_cfg: 
    type: "sgd"
    lr: 1.0e-2
    momentum: 0.95
  lr_schedule_cfg:
    type: 'step'
    milestones: [500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500]
    gamma: 0.9
  early_stopping: False
  validation_freq: 1
  save_best_model: True
  checkpoint_freq: -1
  run_on_gpu: True
  use_amp: True
  log_comet: True
  comet_project_name: 'double-descent-fc1-cifar10-belkin-seed-11'
  seed: *global_seed